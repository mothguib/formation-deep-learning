{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning - Application à la classification d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce TP, nous allons utiliser la technique du transfer learning pour réaliser un classificateur d'images capable de distinguer différents types de nuages :\n",
    "  * cirrus\n",
    "  * cumulus\n",
    "  * cumulonimbus\n",
    "\n",
    "Ce TP est basé sur la leçon n°1 du cours en ligne http://www.fast.ai/.\n",
    "\n",
    "__Attention !__ La version de la librairie fastai utilisée est la 0.7. Ce TP n'est pas compatible avec fastai v1.0 et supérieures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A mettre en haut de chaque notebook afin d'activer certaines fonctionnalités de jupyter notebook\n",
    "\n",
    "# Autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Permet d'afficher les graphiques dans le notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser la librairie de haut niveau fastai.\n",
    "\n",
    "Cette librairie permet de réaliser en très peu de lignes de code certaines tâches classiques de Deep Learning, telles que la classification d'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains all the main external libs we'll use\n",
    "from fastai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PATH` est le chemin d'accès à vos données.\n",
    "\n",
    "`sz` est la taille à laquelle vos images seront redimensionnées, afin d'obtenir un entraînement rapide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/nuages/\"\n",
    "sz=224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifie si le GPU est disponible sur votre machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Jetons un oeil à nos images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pour utiliser les fonctions de classification d'image de la librairie fastai, il faut classer les images dans des répertoires *train* et *valid*. Dans chacun de ces répertoires, il faut un sous-répertoire par classe (dans notre exemple, *cirrus*, *cumulus* et *cumulonimbus*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.listdir(f'{PATH}valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# A quoi ressemblent nos noms de fichiers ?\n",
    "files = os.listdir(f'{PATH}valid/cirrus')[:5]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# A quoi ressemble une image de cirrus ?\n",
    "img = plt.imread(f'{PATH}valid/cirrus/{files[0]}')\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Voici à quoi ressemble la donnée brute pour une image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img[:4,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## C'est parti pour notre premier modèle !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nous allons utiliser un modèle <b>pré-entraîné</b>, c'est-à-dire un modèle créé par quelqu'un d'autre pour classifier d'autres types d'images. Ici nous allons utiliser un modèle entraîné sur le jeu de données ImageNet (1,2 millions d'images et 1000 classes). Ce modèle est un réseau de neurones convolutionnel.\n",
    "\n",
    "Nous allons utiliser le modèle <b>resnet34</b>. Il s'agit du réseau de neurones qui a remporté le challenge ImageNet en 2015.\n",
    "\n",
    "Plus d'infos sur ce modèle : [resnet models](https://github.com/KaimingHe/deep-residual-networks)\n",
    "\n",
    "Et hop, voici comment entraîner notre classificateur de nuages en quatre lignes de code !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Décommenter cette ligne si vous souhaitez recalculer les activations\n",
    "# (en cas de modification du jeu de données images)\n",
    "#shutil.rmtree(f'{PATH}tmp', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arch=resnet34\n",
    "data = ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch, sz))\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=True)\n",
    "learn.fit(0.01, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Que vaut notre modèle ? Il a une précision d'environ 80%, ce qui n'est pas si mal vu le peu d'efforts consentis... Nous verrons plus tard comment faire mieux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Analyse des résultats : regardons quelques images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "En plus des métriques telles que le coût et la précision, il est utile de regarder qualitativement le fonctionnement du modèle :\n",
    "1. Quelques images correctement classifiées, prises au hasard\n",
    "2. Quelques images mal classifiées, prises au hasard\n",
    "3. Les images les plus correctes de chaque classe (celles pour lesquelles le modèle attribue une probabilité élevée d'appartenance à la classe)\n",
    "4. Les images les plus incorrectes de chaque classe (celles pour lesquelles le modèle attribue une probabilité élevée d'appartenance à une autre classe)\n",
    "5. Les images les plus incertaines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Labels du jeu de validation\n",
    "data.val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Permet de savoir à quelle classe correspond le label 0, 1 et 2\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calcul des prédictions pour le jeu de validation. Predictions en échelle logarithmique\n",
    "log_preds = learn.predict()\n",
    "log_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = np.argmax(log_preds, axis=1)  # convertit les log probabilities en classe 0, 1 et 2\n",
    "probs = np.exp(log_preds)        # probabilités en échelle [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rand_by_mask(mask): return np.random.choice(np.where(mask)[0], 4, replace=False)\n",
    "def rand_by_correct(is_correct): return rand_by_mask((preds == data.val_y)==is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_val_with_title(idxs, title):\n",
    "    imgs = np.stack([data.val_ds[x][0] for x in idxs])\n",
    "    title_probs = [probs[x] for x in idxs]\n",
    "    print(title)\n",
    "    return plots(data.val_ds.denorm(imgs), rows=1, titles=title_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12,6), rows=1, titles=None):\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None: sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_img_id(ds, idx): return np.array(PIL.Image.open(PATH+ds.fnames[idx]))\n",
    "\n",
    "def plot_val_with_title(idxs, title):\n",
    "    imgs = [load_img_id(data.val_ds,x) for x in idxs]\n",
    "    title_probs = [probs[x] for x in idxs]\n",
    "    print(title)\n",
    "    return plots(imgs, rows=1, titles=title_probs, figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 1. A few correct labels at random\n",
    "plot_val_with_title(rand_by_correct(True), \"Correctly classified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 2. A few incorrect labels at random\n",
    "plot_val_with_title(rand_by_correct(False), \"Incorrectly classified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def most_by_mask(mask, y):\n",
    "    idxs = np.where(mask)[0]\n",
    "    return idxs[np.argsort(-probs[idxs, y])[:4]]\n",
    "\n",
    "def most_by_correct(y, is_correct): \n",
    "    return most_by_mask(((preds == data.val_y)==is_correct) & (data.val_y == y), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(0, True), \"Cirrus les plus corrects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, True), \"Cumulonimbus les plus corrects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(2, True), \"Cumulus les plus corrects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(0, False), \"Cirrus les plus incorrects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, False), \"Cumulonimbus les plus incorrects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(2, False), \"Cumulus les plus incorrects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_uncertain = np.argsort(np.abs(probs[:,0] - 0.5))[:4]\n",
    "plot_val_with_title(most_uncertain, \"Probabilité de cirrus les plus proches de 0.5 (incertain)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "most_uncertain = np.argsort(np.abs(probs[:,1] - 0.5))[:4]\n",
    "plot_val_with_title(most_uncertain, \"Probabilité de cumulonimbus les plus proches de 0.5 (incertain)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_uncertain = np.argsort(np.abs(probs[:,2] - 0.5))[:4]\n",
    "plot_val_with_title(most_uncertain, \"Probabilité de cumulus les plus proches de 0.5 (incertain)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Améliorons notre modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Si vous continuez d'entraîner votre modèle en augmentant le nombre d'épochs, vous vous apercevrez que le modèle va *overfitter*. D'une certaine manière, il va apprendre par coeur les images du jeu d'entraînement, mais deviendra moins performant losqu'il s'agira de généraliser sur le jeu de validation.\n",
    "\n",
    "Une solution pour éviter ce phénomène est d'ajouter des données d'entraînement. Pour cela, deux solutions :\n",
    "\n",
    "  * Aller chercher d'autres images. C'est évidemment une solution performante, mais potentiellement longue et coûteuse.\n",
    "  * Faire de la *data augmentation*. \n",
    "\n",
    "Nous allons mettre en oeuvre cette seconde solution. La data augmentation va consister à modifier les images lors de l'entraînement, en leur appliquant différentes transformations : miroir, zoom, rotation...\n",
    "\n",
    "Pour cela, nous allons utiliser la fonctionnalité de data augmentation de la librairie fastai. La librairie dispose de fonctions de data augmentation prédéfinies. Nous allons utiliser :\n",
    "\n",
    "  * `transforms_side_on` : rotations et symétrie gauche/droite (pas de symétrie haut/bas, afin de garder les objets \"la tête en haut\")\n",
    "  * `max_zoom` : zoome dans l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(resnet34, sz, aug_tfms=transforms_side_on, max_zoom=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_augs():\n",
    "    data = ImageClassifierData.from_paths(PATH, bs=2, tfms=tfms, num_workers=1)\n",
    "    x,_ = next(iter(data.aug_dl))\n",
    "    return data.trn_ds.denorm(x)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ims = np.stack([get_augs() for i in range(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plots(ims, rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's create a new `data` object that includes this augmentation in the transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = ImageClassifierData.from_paths(PATH, tfms=tfms)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Maintenant que nous avons un bon modèle, nous pouvons le sauvegarder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('224_lastlayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('224_lastlayer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Maintenant que nous avons entraîné la dernière couche, nous pouvons essayer de faire un fine-tuning des autres couches. Pour dire à la librairie que nous voulons *dégeler* les poids de l'ensemble des couches, nous allons utiliser `unfreeze()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Notez que les autres couches ont déjà été entraînées pour reconnaître les photos imagenet (alors que nos couches finales étaient initialisées aléatoirement). Il faut donc veiller à ne pas détruire les poids qui ont déjà été soigneusement entraînés.\n",
    "\n",
    "D'une manière générale, les couches précédentes ont des caractéristiques plus générales. Par conséquent, nous nous attendons à ce qu'ils aient besoin de moins de réglages pour les nouveaux jeux de données. Pour cette raison, nous utiliserons différents learning rates pour différentes couches: les premières couches seront à 1e-4, les couches intermédiaires à 1e-3, et pour nos couches FC nous partirons à 1e-2 comme auparavant. FastAI appelle cela le *differential learning rate*, bien qu'il n'y ait pas de nom officiel dans la littérature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr=np.array([1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Est-ce que le modèle est meilleur ?\n",
    "\n",
    "A votre avis, que s'est-il passé ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('224_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('224_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Une dernière chose que nous pouvons faire avec l'augmentation des données est de l'utiliser lors de l'inférence. C'est une technique appellée *Test Time Augmentation* (TTA).\n",
    "\n",
    "TTA effectue simplement des prédictions non seulement sur les images du jeu de validation, mais également avec un certain nombre de versions augmentées de manière aléatoire (par défaut, l'image originale et 4 versions augmentées de façon aléatoire). Il prend alors la prédiction moyenne de ces images.\n",
    "\n",
    "C'est le même principe qu'en prévision d'ensemble météo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_preds,y = learn.TTA()\n",
    "probs = np.mean(np.exp(log_preds),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accuracy_np(probs, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "On peut en général espérer autour de 10 à 20% de réduction de l'erreur grâce au TTA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = np.argmax(probs, axis=1)\n",
    "#probs = probs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nous pouvons afficher la matrice de contingence sous une forme graphique (ce qui est pratique lorsqu'on a un nombre important de classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Revoyons nos images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(0, False), \"Cirrus les plus incorrects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, False), \"Cumulonimbus les plus incorrects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(2, False), \"Cumulus les plus incorrects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Résumé :\n",
    "<b>Comment entraîner un classificateur d'image au top niveau international grâce au transfer learning !</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Récupérer un modèle pré-entraîné\n",
    "1. Entraîner la dernière couche pour quelques epochs, en veillant à ne pas overfitter\n",
    "1. Entraîner la dernière couche avec data augmentation\n",
    "1. Dégeler les autres couches et entraîner pour le fine-tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
